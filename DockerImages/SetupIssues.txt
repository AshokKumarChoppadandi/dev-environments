Zookeeper Quorum:

    Four Letter commands are not working

Elasticsearch :

    Need to set vm.max_map_count=262144

    Docker Desktop for Windows:

    wsl -d docker-desktop
    sysctl -w vm.max_map_count=262144

PostgresSQL:

    To access PostgreSQL outside the node i.e., from different server:
        1. Default installation location if installed with dnf / yum is - /var/lib/pgsql
        2. Initially PostgreSQL is accessed only with the postgres user (created at the time of installation)
        3. To access psql shell - sudo -iu postgres
        4. Create a User Role and Password
             CREATE USER bigdata WITH PASSWORD 'Bigdata@123';
             CREATE DATABASE bigdatadb;
             GRANT ALL PRIVILEGES ON DATABASE bigdatadb to bigdata;
        5. All other connections to access the PostgreSQL Server by making - listener_address = '*'
           in /var/lib/pgsql/13/data/postgresql.conf file
        6. Edit /var/lib/pgsql/13/data/pg_hba.conf to allow other user access the PostgreSQL Server from outside the node.
             # IPv4 local connections:
             host    all             all             127.0.0.1/32            md5
             host    all             all             0.0.0.0/0               md5
             host    all             all             localhost               md5
        7. Disable the firewall. In CentOS 7 / 8
            systemctl stop firewalld.service
            systemctl disable firewalld.service
        7. psql -h <hostname> -p <port> -U <userName> <dbName>

            Ex:
                psql -h localhost -p 5432 -U bigdata bigdatadb
                psql -h 127.0.0.1 -p 5432 -U bigdata bigdatadb
                psql -h 192.168.0.144 -p 5432 -U bigdata bigdatadb

CentOS 8:

    Issue: Unable to download using yum or dnf

    When executing the below commands, it was failing because:

        CentOS 8 reached its end-of-life on December 31st, 2021, and thus, since January 31st, 2022, repositories for that OS were disabled by its vendor and archived to https://vault.centos.org/.

    dnf update -y or yum update -y

    Error:

    Failed to download metadata for repo 'appstream': Cannot prepare internal mirrorlist: No URLs in mirrorlist

    Resolution:

       wget 'http://mirror.centos.org/centos/8-stream/BaseOS/x86_64/os/Packages/centos-gpg-keys-8-3.el8.noarch.rpm'

       sudo rpm -i 'centos-gpg-keys-8-3.el8.noarch.rpm'

       sudo dnf --disablerepo '*' --enablerepo=extras swap centos-linux-repos centos-stream-repos -y

       If the command fails with below error

       Error: Problem: problem with installed package centos-release-stream-8.1-1.1911.0.7.el8.x86_64

       Then try using --allowerasing like below:

       sudo dnf --disablerepo '*' --enablerepo=extras swap centos-linux-repos centos-stream-repos --allowerasing -y

       sudo dnf distro-sync -y

       If the above steps doesn't work, download the latest GPG Keys rpm file from the below link:

       http://mirror.centos.org/centos/8-stream/BaseOS/x86_64/os/Packages/

Rolling Restart:

    Note: The Kafka configuration file should only be ending with .yaml. The other extension like .yml is not accepted.
    Issue: CentOS 8 / Python 3 issue while installing yelp tools / kafka-utils

    Error: Command "python setup.py egg_info" failed with error code 1

    Resolution:

        sudo pip3 install --upgrade pip

        pip3 install kafka-utils --user bigdata

        OR

        Installed Python 2 and pip 2 which resolved the issue

        pip2 install kafka-utils --user bigdata

Passwordless Login:

    Issue: The issue key generated by openssh using ssh-keygen is different for RSA
    Error: paramiko.ssh_exception.SSHException: not a valid RSA private key file
    Resolution:

        The private need to convert from Open SSH to RSA
        To Convert "BEGIN OPENSSH PRIVATE KEY" to "BEGIN RSA PRIVATE KEY" using the following command

        ssh-keygen -p -m PEM -f ~/.ssh/id_rsa

LinkedIn Kafka Tools:

    Issue:

    kafka-assigner will look for the kafka binaries (kafka-reassign-partitions.sh) which are with .sh extension.
    If Apache Kafka is installed then there will be no issue, but if we have Confluent Kafka installed then kafka-assigner command will not be able to find the binaries because there will be no .sh extension for the script.

    Error:

    kafka.tools.exceptions.ConfigurationException: Cannot find the Kafka admin utilities using PATH. Try using the --tools-path option

    OR

    FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/confluent/bin/kafka-preferred-replica-election.sh': '/usr/local/confluent/bin/kafka-preferred-replica-election.sh'

    Resolution:

    To resolve it, create a soft link:

    sudo ln -s /usr/local/confluent/bin/kafka-reassign-partitions /usr/local/confluent/bin/kafka-reassign-partitions.sh
    sudo ln -s /usr/local/confluent/bin/kafka-preferred-replica-election /usr/local/confluent/bin/kafka-preferred-replica-election.sh



kafka-avro-console-producer \
 --broker-list 192.168.0.211:9092,192.168.0.212:9092,192.168.0.213:9092, \
 --topic Test  \
 --property schema.registry.url=http://localhost:8081 \
 --property value.schema.id=2

{"f1": "value1"}
{"f1": "value2"}
{"f1": "value3"}

kafka-avro-console-consumer \
  --bootstrap-server 192.168.0.211:9092,192.168.0.212:9092,192.168.0.213:9092 \
  --topic Test \
  --from-beginning \
  --property schema.registry.url=http://localhost:8081 \
  --property print.key=true \
  --property print.value=true \
  --property key.separator='|'


kafka-avro-console-producer \
 --broker-list 192.168.0.211:9092,192.168.0.212:9092,192.168.0.213:9092, \
 --topic employee  \
 --property schema.registry.url=http://192.168.0.134:8081 \
 --property value.schema.id=1

{"eid": 111, "ename": "Ashok Kumar Choppdandi", "esalary": 10000, "edept": "CSE", "eage": 31}
{"eid": 222, "ename": "Anusha Choppdandi", "esalary": 15000, "edept": "MECH", "eage": 26}


kafka-avro-console-consumer \
  --bootstrap-server 192.168.0.211:9092,192.168.0.212:9092,192.168.0.213:9092 \
  --topic employee \
  --from-beginning \
  --property schema.registry.url=http://192.168.0.134:8081 \
  --property print.key=true \
  --property print.value=true \
  --property key.separator='|'

